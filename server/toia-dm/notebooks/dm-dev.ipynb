{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deeeb555-bc77-4457-bb8f-d1403a06f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1353aae9-ff9d-4967-a1f1-7512dd821948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "from sqlalchemy.sql import text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import re\n",
    "import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import spacy\n",
    "NLP = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18ba4c61-c95d-4488-8a07-9aff189551b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "avatar_id = '1'\n",
    "stream_id = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e12b33cc-d96d-496e-bb70-c04dccfc4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_url = \"mysql+mysqlconnector://root:3bR}M5Jz%d$7@localhost/toia\"\n",
    "\n",
    "engine = db.create_engine(sql_url)\n",
    "connection = engine.connect()\n",
    "metadata = db.MetaData()\n",
    "# videos = db.Table('video', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# avatar_kb = db.select([videos]).where(\n",
    "#     videos.columns.toia_id == avatar_id,\n",
    "#     videos.columns.private == 0,\n",
    "#     videos.columns.type.notin_([\"filler\", \"exit\"])\n",
    "# )\n",
    "\n",
    "statement = text(f\"\"\"SELECT stream_has_video.stream_id_stream, video.* \n",
    "    FROM video \n",
    "    INNER JOIN stream_has_video \n",
    "    ON video.id_video = stream_has_video.video_id_video \n",
    "    WHERE stream_id_stream = {stream_id}\n",
    "    AND toia_id = {avatar_id}\n",
    "    AND private = 0\n",
    "    AND type NOT IN ('filler', 'exit');\"\"\")\n",
    "\n",
    "# ResultProxy = connection.execute(avatar_kb)\n",
    "ResultProxy = connection.execute(statement)\n",
    "ResultSet = ResultProxy.fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45882754-fedc-4c6c-90fe-f281fba54080",
   "metadata": {},
   "source": [
    "SQL equivalent to:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43cd31c5-5364-44de-b7c2-ccd7c8bcaf47",
   "metadata": {},
   "source": [
    "SELECT stream_has_video.stream_id_stream, video.* \n",
    "    FROM video \n",
    "    INNER JOIN stream_has_video \n",
    "    ON video.id_video = stream_has_video.video_id_video \n",
    "    WHERE stream_id_stream = <stream_id>;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e88f7e56-4734-4472-8401-f33279ca9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avatar = pd.DataFrame(ResultSet, \n",
    "             columns=[\n",
    "                 'stream_id_stream',\n",
    "                 'id_video', \n",
    "                 'type', \n",
    "                 'toia_id', \n",
    "                 'idx', \n",
    "                 'private', \n",
    "                 'question', \n",
    "                 'answer', \n",
    "                 'language', \n",
    "                 'likes', \n",
    "                 'views',\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f9f0827-9536-4eed-b240-2c4461566bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stream_id_stream</th>\n",
       "      <th>id_video</th>\n",
       "      <th>type</th>\n",
       "      <th>toia_id</th>\n",
       "      <th>idx</th>\n",
       "      <th>private</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>language</th>\n",
       "      <th>likes</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alberto_1_3_4958c7ed.mp4</td>\n",
       "      <td>greeting</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Record a greeting!</td>\n",
       "      <td>hello there. How's it going?</td>\n",
       "      <td>EN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Alberto_1_4_2dacf448.mp4</td>\n",
       "      <td>answer</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Where are you from?</td>\n",
       "      <td>I come from Italy</td>\n",
       "      <td>EN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stream_id_stream                  id_video      type  toia_id  idx  \\\n",
       "0                 1  Alberto_1_3_4958c7ed.mp4  greeting        1    3   \n",
       "1                 1  Alberto_1_4_2dacf448.mp4    answer        1    4   \n",
       "\n",
       "   private             question                        answer language  likes  \\\n",
       "0        0   Record a greeting!  hello there. How's it going?       EN      0   \n",
       "1        0  Where are you from?             I come from Italy       EN      0   \n",
       "\n",
       "   views  \n",
       "0      0  \n",
       "1      0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avatar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f1d383b-f0c4-4fcf-8758-3a70d083949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- next doc ---\n",
      "Record a greeting!\n",
      "Record VERB VB\n",
      "a DET DT\n",
      "greeting NOUN NN\n",
      "! PUNCT .\n",
      "--- next doc ---\n",
      "Where are you from?\n",
      "Where ADV WRB\n",
      "are AUX VBP\n",
      "you PRON PRP\n",
      "from ADP IN\n",
      "? PUNCT .\n"
     ]
    }
   ],
   "source": [
    "docs = NLP.pipe(df_avatar['question'].values)\n",
    "for doc in docs:\n",
    "    print(\"--- next doc ---\")\n",
    "    print(doc)\n",
    "    for token in doc:\n",
    "        print(token.text, token.pos_, token.tag_)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba228ea6-23a1-4fe1-b0d3-a3e837b1ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = NLP(\"hey, hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9074bb1a-720d-41cc-9239-76ea15022d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['INTJ', 'UH'] in [[token.pos_, token.tag_] for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f0f3649-fba5-4515-abdc-7e84c3e784ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',', '.', 'UH'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([token.tag_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c4f751d-c475-4465-b6c0-7637647fe331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_greetings = df_avatar[df_avatar['type'] == \"greeting\"]\n",
    "if df_greetings.shape[0] > 0:\n",
    "    df_greetings.sample(n=1)['answer'].values[0]\n",
    "else:\n",
    "    print(\"204 No Content: you haven't recorded greetings\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bebbb785-0e26-4938-a4e6-5bbe15691122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(text1, text2):\n",
    "    base = NLP(process_text(text1))\n",
    "    compare = NLP(process_text(text2))\n",
    "    return base.similarity(compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4b14530-483d-4437-a5ad-36ec9df0fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    doc = NLP(text.lower())\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        if token.text in NLP.Defaults.stop_words:\n",
    "            continue\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        if token.lemma_ == '-PRON-':\n",
    "            continue\n",
    "        result.append(token.lemma_)\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bb204c7-cd82-4bc9-bec4-d0e3d87f0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = SnowballStemmer('english')\n",
    "\n",
    "def preprocess(text):\n",
    "            # Stem and remove stopwords\n",
    "            text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "            text = text.lower()\n",
    "            text = text.split()\n",
    "            text = [ps.stem(word) for word in text]  # if not word in set(stopwords.words('english'))]\n",
    "            return ' '.join(text)\n",
    "\n",
    "\n",
    "def toia_answer(query, dataset, k=1):\n",
    "    doc = NLP(query)\n",
    "    # if Greeting, greet\n",
    "    if ['INTJ', 'UH'] in [[token.pos_, token.tag_] for token in doc]:    \n",
    "        if df_greetings.shape[0] > 0:\n",
    "            answers = dataset[dataset['type'] == \"greeting\"].sample(n=1)\n",
    "            return answers['answer'].values[0], answers['id_video'].values[0]\n",
    "        else:\n",
    "            df_noanswers = dataset[dataset['type'] == \"no-answer\"]\n",
    "            if df_noanswers.shape[0] > 0:\n",
    "                answers = df_noanswers.sample(n=1)\n",
    "                return answers['answer'].values[0], answers['id_video'].values[0], \"Record some reetings\"\n",
    "            else:\n",
    "                return \"You haven't recorded greetings nor no-answers\", \"204\", \"No Content\"\n",
    "\n",
    "    querycorpus = []\n",
    "    for i in range(0, len(dataset)):\n",
    "        userquestion = preprocess(dataset['question'][i])\n",
    "        querycorpus.append(userquestion)\n",
    "\n",
    "    # Creating the Bag of Words model with TFIDF and calc cosine_similarity\n",
    "    vectorizer = CountVectorizer(decode_error=\"replace\")\n",
    "    # this is needed to get the attribute vocabulary_\n",
    "    vec_train = vectorizer.fit_transform(querycorpus)\n",
    "    training_vocabulary = vectorizer.vocabulary_\n",
    "    transformer = TfidfTransformer()\n",
    "    trainingvoc_vectorizer = CountVectorizer(\n",
    "        decode_error=\"replace\", vocabulary=training_vocabulary)\n",
    "    tfidf_querycorpus = TfidfVectorizer().fit_transform(querycorpus)\n",
    "\n",
    "    tfidf_userquestion = transformer.fit_transform(\n",
    "        trainingvoc_vectorizer.fit_transform(\n",
    "            numpy.array([\n",
    "                preprocess(query)\n",
    "            ])))\n",
    "    cosine_similarities = cosine_similarity(tfidf_userquestion, tfidf_querycorpus)\n",
    "    related_docs_indices = (-cosine_similarities[0]).argsort()\n",
    "    sorted_freq = cosine_similarities[0][related_docs_indices]\n",
    "\n",
    "    # note for this distance the problem we had befor with inf, we have now with 0. Again we decide\n",
    "    # to make the prediction a bit random. This could be adjusted to remove any 0 distance and\n",
    "    # pick the only ones left if any, and if none predict 1.\n",
    "\n",
    "    if sum(sorted_freq) == 0:\n",
    "        df_noanswers = dataset[dataset['type'] == \"no-answer\"]\n",
    "        if df_noanswers.shape[0] > 0:\n",
    "            answers = df_noanswers.sample(n=1)\n",
    "            return answers['answer'].values[0], answers['id_video'].values[0], \"tfidf all sim 0\"\n",
    "        else:\n",
    "            return \"You haven't recorded no-answers\", \"204\", \"No Content\"\n",
    "    elif sorted_freq[0] > 0.7:  #(the top sorted freq is the max)\n",
    "        if sorted_freq[k-1] != sorted_freq[k] or sorted_freq[k-1] == sorted_freq[k] == 0:\n",
    "            selected = related_docs_indices[:k]\n",
    "            return dataset.iloc[selected[0]]['answer'], dataset.iloc[selected[0]]['id_video'], f\"tfidf sim: {sorted_freq[:k]}\"\n",
    "        else:\n",
    "            indeces = numpy.where(numpy.roll(sorted_freq, 1) != sorted_freq)\n",
    "            selected = related_docs_indices[:indeces[0][indeces[0] >= k][0]]\n",
    "            return dataset.iloc[selected[0]]['answer'], dataset.iloc[selected[0]]['id_video'], f\"tfidf sim: {sorted_freq[:k]}\"\n",
    "\n",
    "    else:\n",
    "        docs = NLP.pipe(dataset['question'].values)\n",
    "        cosine_similarities = [calculate_similarity(query, doc.text) for doc in docs]\n",
    "        if max(cosine_similarities) > 0.5:\n",
    "            related_docs_indices = np.argsort(cosine_similarities)[::-1]\n",
    "            selected = related_docs_indices[:k][0]\n",
    "            return dataset.iloc[selected]['answer'], dataset.iloc[selected]['id_video'], f\"spaCy sim: {cosine_similarities[selected]}\"\n",
    "        else:\n",
    "            df_noanswers = dataset[dataset['type'] == \"no-answer\"]\n",
    "            if df_noanswers.shape[0] > 0:\n",
    "                answers = df_noanswers.sample(n=1)\n",
    "                return answers['answer'].values[0], answers['id_video'].values[0], \"spaCy sim below thr\"\n",
    "            else:\n",
    "                return \"You haven't recorded no-answers\", \"204\", \"No Content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cd47cf2-2ea4-42cb-9bc3-9d9127053b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yh/m455kn5x5pbgwq0gg3dt4xtc0000gn/T/ipykernel_15125/2174577701.py:4: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  return base.similarity(compare)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"You haven't recorded no-answers\", '204', 'No Content')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toia_answer(\"Do you like\", df_avatar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1630e-89fd-4eb7-8d9a-a88c0ad1d7ff",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dee8b9-ebd5-4230-9869-182b193e9f20",
   "metadata": {},
   "source": [
    "## Experiment with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "820f850f-d2cc-42b7-ae3d-2d185fdbfcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yh/m455kn5x5pbgwq0gg3dt4xtc0000gn/T/ipykernel_15125/2174577701.py:4: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  return base.similarity(compare)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1750639131172708, 0.0]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = NLP.pipe(df_avatar['question'].values)\n",
    "similar_list = [calculate_similarity(\"Yo!\", doc.text) for doc in docs]\n",
    "similar_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ddb2ba8e-45a6-46ea-8b21-f71d0569cefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Record a greeting!', 0.1750639131172708), ('Where are you from?', 0.0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(df_avatar.loc[j, 'question'], i) for\n",
    " i, j in zip(\n",
    "     np.sort(similar_list)[::-1], \n",
    "     np.argsort(similar_list)[::-1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485590a0-eeff-4fd8-a502-8c73f5ebd3a2",
   "metadata": {},
   "source": [
    "### Test new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6b53024-656e-4af6-aa56-1f8806001ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"what's your name\"\n",
    "# dataset = df_avatar.copy()\n",
    "# k = 1\n",
    "\n",
    "def toia_answer_new(query, dataset, k=1):\n",
    "    doc = NLP(query)\n",
    "    # if Greeting, greet\n",
    "    if ['INTJ', 'UH'] in [[token.pos_, token.tag_] for token in doc]:\n",
    "        if dataset[dataset['type'] == \"greeting\"].shape[0] > 0:\n",
    "            answers = dataset[dataset['type'] == \"greeting\"].sample(n=1)\n",
    "            return answers['answer'].values[0], answers['id_video'].values[0]\n",
    "        else:\n",
    "            answers = dataset[dataset['type'] == \"no-answer\"].sample(n=1)\n",
    "            return answers['answer'].values[0], answers['id_video'].values[0], \"No greetings recorded\"\n",
    "\n",
    "    querycorpus = []\n",
    "    for i in range(0, len(dataset)):\n",
    "        userquestion = preprocess(dataset['question'][i])\n",
    "        querycorpus.append(userquestion)\n",
    "\n",
    "    # Creating the Bag of Words model with TFIDF and calc cosine_similarity\n",
    "    vectorizer = CountVectorizer(decode_error=\"replace\")\n",
    "    # this is needed to get the attribute vocabulary_\n",
    "    vec_train = vectorizer.fit_transform(querycorpus)\n",
    "    training_vocabulary = vectorizer.vocabulary_\n",
    "    transformer = TfidfTransformer()\n",
    "    trainingvoc_vectorizer = CountVectorizer(\n",
    "        decode_error=\"replace\", vocabulary=training_vocabulary)\n",
    "    tfidf_querycorpus = TfidfVectorizer().fit_transform(querycorpus)\n",
    "\n",
    "    tfidf_userquestion = transformer.fit_transform(\n",
    "        trainingvoc_vectorizer.fit_transform(\n",
    "            numpy.array([\n",
    "                preprocess(query)\n",
    "            ])))\n",
    "    cosine_similarities = cosine_similarity(tfidf_userquestion, tfidf_querycorpus)\n",
    "    related_docs_indices = (-cosine_similarities[0]).argsort()\n",
    "    sorted_freq = cosine_similarities[0][related_docs_indices]\n",
    "\n",
    "    # note for this distance the problem we had befor with inf, we have now with 0. Again we decide\n",
    "    # to make the prediction a bit random. This could be adjusted to remove any 0 distance and\n",
    "    # pick the only ones left if any, and if none predict 1.\n",
    "\n",
    "    if sum(sorted_freq) == 0:\n",
    "        answers = dataset[dataset['type'] == \"no-answer\"].sample(n=1)\n",
    "        return answers['answer'].values[0], answers['id_video'].values[0], \"tfidf sim all 0\"\n",
    "\n",
    "    elif sorted_freq[0] > 0.7:  #(the top sorted freq is the max)\n",
    "        if sorted_freq[k-1] != sorted_freq[k] or sorted_freq[k-1] == sorted_freq[k] == 0:\n",
    "            selected = related_docs_indices[:k]\n",
    "            return dataset.iloc[selected[0]]['answer'], dataset.iloc[selected[0]]['id_video'], f\"tfidf sim: {sorted_freq[:k]}\"\n",
    "        else:\n",
    "            indeces = numpy.where(numpy.roll(sorted_freq, 1) != sorted_freq)\n",
    "            selected = related_docs_indices[:indeces[0][indeces[0] >= k][0]]\n",
    "            return dataset.iloc[selected[0]]['answer'], dataset.iloc[selected[0]]['id_video'], f\"tfidf sim: {sorted_freq[:k]}\"\n",
    "\n",
    "    else:\n",
    "        docs = NLP.pipe(dataset['question'].values)\n",
    "        cosine_similarities = [calculate_similarity(query, doc.text) for doc in docs]\n",
    "        if max(cosine_similarities) > 0.5:\n",
    "            related_docs_indices = np.argsort(cosine_similarities)[::-1]\n",
    "            selected = related_docs_indices[:k][0]\n",
    "            return dataset.iloc[selected]['answer'], dataset.iloc[selected]['id_video'], f\"spaCy sim: {cosine_similarities[selected]}\"\n",
    "        else:\n",
    "            answers = dataset[dataset['type'] == \"no-answer\"].sample(n=1)\n",
    "            return answers['answer'].values[0], answers['id_video'].values[0], f\"spaCy sim: {max(cosine_similarities)}\"\n",
    "\n",
    "            \n",
    "# For testing function, convert all 'return' to 'return_a ='\n",
    "# return_a  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b0ae6c4-4193-46a8-bfeb-dfd1dc856f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_toia(dataset):\n",
    "    print(\"TOIA starts\")\n",
    "\n",
    "    while True:\n",
    "        query = input('> ')\n",
    "        if query == \"stop\":\n",
    "            break\n",
    "\n",
    "        output = toia_answer_new(query, dataset)\n",
    "        if output is None:\n",
    "            break\n",
    "\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0f76aba-77c3-40dc-a8a5-c998b901693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOIA starts\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"hello there. How's it going?\", 'Alberto_1_3_4958c7ed.mp4')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  where are you from\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I come from Italy', 'Alberto_1_4_2dacf448.mp4', 'tfidf sim: [1.]')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  are you from where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I come from Italy', 'Alberto_1_4_2dacf448.mp4', 'tfidf sim: [1.]')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  where were you born\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I come from Italy', 'Alberto_1_4_2dacf448.mp4', 'tfidf sim: [0.70710678]')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  stop\n"
     ]
    }
   ],
   "source": [
    "run_toia(df_avatar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd108ac-5484-4050-978e-b633313ffc99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4370f583-2e6d-4c15-af35-688d36a33c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ed2f287-2bf7-4b24-b5b6-7c2fb53d0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = sr.Microphone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15d77f2e-986c-4fd6-874b-0a493f7e63c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alberto Maria Chierici’s AirPods Max',\n",
       " 'Alberto Maria Chierici’s AirPods Max',\n",
       " 'MacBook Pro Microphone',\n",
       " 'MacBook Pro Speakers',\n",
       " 'Multi-Output Device']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92409336-b888-4f27-aeb7-2991ef3bb630",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mic as source:\n",
    "    # r.adjust_for_ambient_noise(source)\n",
    "    audio = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "351aaf49-8296-4ae7-a3a4-84d38137be82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ae20b6d-fb1d-4bec-89ce-ef73423f5db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_toia(dataset):\n",
    "    print(\"TOIA starts\")\n",
    "\n",
    "    while True:\n",
    "        # query = input('> ')\n",
    "        with mic as source:\n",
    "            print(\"you may speak ...\")\n",
    "            # r.adjust_for_ambient_noise(source)\n",
    "            audio = r.listen(source)\n",
    "            query = r.recognize_google(audio)\n",
    "            print(f\"(you said {query})\")\n",
    "        if query == \"stop\":\n",
    "            break\n",
    "\n",
    "        output = toia_answer_new(query, dataset)\n",
    "        if output is None:\n",
    "            break\n",
    "\n",
    "        print(f\"avatar: {output[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4bb6f35f-4ddd-4198-b424-e3fd876c3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOIA starts\n",
      "you may speak ...\n",
      "(you said hello where are you)\n",
      "avatar: hello there. How's it going?\n",
      "you may speak ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yh/m455kn5x5pbgwq0gg3dt4xtc0000gn/T/ipykernel_15125/1924364141.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_toia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_avatar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/yh/m455kn5x5pbgwq0gg3dt4xtc0000gn/T/ipykernel_15125/3405446147.py\u001b[0m in \u001b[0;36mrun_toia\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you may speak ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# r.adjust_for_ambient_noise(source)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"(you said {query})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/toia-dm-mv9iBiCR/lib/python3.8/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[1;32m    650\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                 \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# reached end of the stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                 \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/toia-dm-mv9iBiCR/lib/python3.8/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/toia-dm-mv9iBiCR/lib/python3.8/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_toia(df_avatar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c768d1-6aa7-447d-8535-5262ac745cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9db9272-4b20-453e-8bff-2aff711905fd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93bca89-98ca-4462-bcc9-7e15de0013f9",
   "metadata": {},
   "source": [
    "## WIP: Can see if an ELIZA-like algorithm can help\n",
    "\n",
    "https://github.com/wadetb/eliza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f211ad7e-149c-462d-a101-ed309b92e538",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e2ffbe54-c168-4e86-be33-d0c646533100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install https://github.com/MartinoMensio/spacy-sentence-bert/releases/download/v0.1.2/en_paraphrase_distilroberta_base_v1-0.1.2.tar.gz#en_paraphrase_distilroberta_base_v1-0.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "1353aae9-ff9d-4967-a1f1-7512dd821948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "from sqlalchemy.sql import text\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import spacy\n",
    "import spacy_sentence_bert\n",
    "NLP = spacy.load(\"en_core_web_lg\")\n",
    "# NLP_BERT = spacy.load(\"en_paraphrase_distilroberta_base_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "1a13e027-2066-4fc9-be10-47d5a69bd838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence_bert']"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NLP_BERT = spacy_sentence_bert.load_model('multi-qa-mpnet-base-dot-v1')\n",
    "NLP_BERT = spacy.blank('en')\n",
    "NLP_BERT.add_pipe('sentence_bert', config={'model_name': 'multi-qa-MiniLM-L6-cos-v1'})\n",
    "NLP_BERT.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "18ba4c61-c95d-4488-8a07-9aff189551b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_id = '9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "e12b33cc-d96d-496e-bb70-c04dccfc4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_url = \"mysql+mysqlconnector://root:ReallyComplicatedPassword@34.77.217.30:3307/toia\"\n",
    "\n",
    "engine = db.create_engine(sql_url)\n",
    "connection = engine.connect()\n",
    "metadata = db.MetaData()\n",
    "\n",
    "statement = text(f\"\"\"\n",
    "    SELECT vqs.id_stream as stream_id_stream, \n",
    "        vqs.type, q.question, v.answer, v.id_video\n",
    "    FROM video v\n",
    "    JOIN videos_questions_streams vqs ON vqs.id_video = v.id_video\n",
    "    JOIN questions q ON q.id = vqs.id_question\n",
    "    WHERE vqs.id_stream = {stream_id}\n",
    "    AND v.private = 0 \n",
    "    AND vqs.type NOT IN ('filler');\"\"\")\n",
    "\n",
    "# ResultProxy = connection.execute(avatar_kb)\n",
    "ResultProxy = connection.execute(statement)\n",
    "ResultSet = ResultProxy.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "e88f7e56-4734-4472-8401-f33279ca9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avatar = pd.DataFrame(ResultSet, \n",
    "             columns=[\n",
    "                 'stream_id_stream',\n",
    "                 'type',\n",
    "                 'question',\n",
    "                 'answer',\n",
    "                 'id_video'\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "4f9f0827-9536-4eed-b240-2c4461566bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stream_id_stream</th>\n",
       "      <th>type</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>id_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>answer</td>\n",
       "      <td>What is your name?</td>\n",
       "      <td>My name is Chloe.</td>\n",
       "      <td>toia181_9_250_79387bf3.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>answer</td>\n",
       "      <td>What do you do for a living?</td>\n",
       "      <td>I am a student.</td>\n",
       "      <td>toia181_9_252_10af5fb6.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>no-answer</td>\n",
       "      <td>Say: Sorry, I didn't record answers to that qu...</td>\n",
       "      <td>Sorry, I didn't record an answer to that quest...</td>\n",
       "      <td>toia181_9_253_992ebf88.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>no-answer</td>\n",
       "      <td>Say: I don't have an answer to that right now.</td>\n",
       "      <td>I don't have an answer to that right.</td>\n",
       "      <td>toia181_9_254_e636fa66.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>answer</td>\n",
       "      <td>What is your favorite color?</td>\n",
       "      <td>My favorite color is probably black. That, I k...</td>\n",
       "      <td>toia181_9_255_af2a709b.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>9</td>\n",
       "      <td>answer</td>\n",
       "      <td>do you like tonic water?</td>\n",
       "      <td>I think it's okay, but I'm not necessarily par...</td>\n",
       "      <td>toia181_9_444_5cd698b0.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>9</td>\n",
       "      <td>answer</td>\n",
       "      <td>do you like purple?</td>\n",
       "      <td>I think it's okay, but I'm not necessarily par...</td>\n",
       "      <td>toia181_9_444_5cd698b0.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>9</td>\n",
       "      <td>answer</td>\n",
       "      <td>What are your hobbies?</td>\n",
       "      <td>My hobbies are probably learning, cooking and ...</td>\n",
       "      <td>toia181_9_445_3a3c3f91.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>9</td>\n",
       "      <td>answer</td>\n",
       "      <td>Do you cook often?</td>\n",
       "      <td>Yes, I cook whenever I have time or if I have ...</td>\n",
       "      <td>toia181_9_446_f582922f.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>9</td>\n",
       "      <td>answer</td>\n",
       "      <td>Do you like to drink?</td>\n",
       "      <td>I like to drink occasionally. But not too much.</td>\n",
       "      <td>toia181_9_447_c3454e93.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     stream_id_stream       type  \\\n",
       "0                   9     answer   \n",
       "1                   9     answer   \n",
       "2                   9  no-answer   \n",
       "3                   9  no-answer   \n",
       "4                   9     answer   \n",
       "..                ...        ...   \n",
       "189                 9     answer   \n",
       "190                 9     answer   \n",
       "191                 9     answer   \n",
       "192                 9     answer   \n",
       "193                 9     answer   \n",
       "\n",
       "                                              question  \\\n",
       "0                                   What is your name?   \n",
       "1                         What do you do for a living?   \n",
       "2    Say: Sorry, I didn't record answers to that qu...   \n",
       "3       Say: I don't have an answer to that right now.   \n",
       "4                         What is your favorite color?   \n",
       "..                                                 ...   \n",
       "189                           do you like tonic water?   \n",
       "190                                do you like purple?   \n",
       "191                             What are your hobbies?   \n",
       "192                                 Do you cook often?   \n",
       "193                              Do you like to drink?   \n",
       "\n",
       "                                                answer  \\\n",
       "0                                    My name is Chloe.   \n",
       "1                                      I am a student.   \n",
       "2    Sorry, I didn't record an answer to that quest...   \n",
       "3                I don't have an answer to that right.   \n",
       "4    My favorite color is probably black. That, I k...   \n",
       "..                                                 ...   \n",
       "189  I think it's okay, but I'm not necessarily par...   \n",
       "190  I think it's okay, but I'm not necessarily par...   \n",
       "191  My hobbies are probably learning, cooking and ...   \n",
       "192  Yes, I cook whenever I have time or if I have ...   \n",
       "193    I like to drink occasionally. But not too much.   \n",
       "\n",
       "                       id_video  \n",
       "0    toia181_9_250_79387bf3.mp4  \n",
       "1    toia181_9_252_10af5fb6.mp4  \n",
       "2    toia181_9_253_992ebf88.mp4  \n",
       "3    toia181_9_254_e636fa66.mp4  \n",
       "4    toia181_9_255_af2a709b.mp4  \n",
       "..                          ...  \n",
       "189  toia181_9_444_5cd698b0.mp4  \n",
       "190  toia181_9_444_5cd698b0.mp4  \n",
       "191  toia181_9_445_3a3c3f91.mp4  \n",
       "192  toia181_9_446_f582922f.mp4  \n",
       "193  toia181_9_447_c3454e93.mp4  \n",
       "\n",
       "[194 rows x 5 columns]"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avatar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "0f1d383b-f0c4-4fcf-8758-3a70d083949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = NLP.pipe(df_avatar['question'].values)\n",
    "# for doc in docs:\n",
    "#     print(\"--- next doc ---\")\n",
    "#     print(doc)\n",
    "#     for token in doc:\n",
    "#         print(token.text, token.pos_, token.tag_)\n",
    "#     for ent in doc.ents:\n",
    "#         print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "ba228ea6-23a1-4fe1-b0d3-a3e837b1ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = NLP(\"hey, hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "9074bb1a-720d-41cc-9239-76ea15022d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['INTJ', 'UH'] in [[token.pos_, token.tag_] for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "8f0f3649-fba5-4515-abdc-7e84c3e784ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',', '.', 'UH'}"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([token.tag_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "3c4f751d-c475-4465-b6c0-7637647fe331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_greetings = df_avatar[df_avatar['type'] == \"greeting\"]\n",
    "if df_greetings.shape[0] > 0:\n",
    "    df_greetings.sample(n=1)['answer'].values[0]\n",
    "else:\n",
    "    print(\"204 No Content: you haven't recorded greetings\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "d4b14530-483d-4437-a5ad-36ec9df0fd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    doc = NLP(text.lower())\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        if token.text in NLP.Defaults.stop_words:\n",
    "            continue\n",
    "        if token.is_punct:\n",
    "            continue\n",
    "        if token.lemma_ == '-PRON-':\n",
    "            continue\n",
    "        result.append(token.lemma_)\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "bebbb785-0e26-4938-a4e6-5bbe15691122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(text1, text2):\n",
    "    base = NLP(process_text(text1))\n",
    "    compare = NLP(process_text(text2))\n",
    "    return base.similarity(compare)\n",
    "# def calculate_similarity(text1, text2):\n",
    "#     base = NLP_BERT(text1)\n",
    "#     compare = NLP_BERT(text2)\n",
    "#     return base.similarity(compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "0bb204c7-cd82-4bc9-bec4-d0e3d87f0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = SnowballStemmer('english')\n",
    "\n",
    "def preprocess(text):\n",
    "            # Stem and remove stopwords\n",
    "            text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "            text = text.lower()\n",
    "            text = text.split()\n",
    "            text = [ps.stem(word) for word in text]  # if not word in set(stopwords.words('english'))]\n",
    "            return ' '.join(text)\n",
    "\n",
    "\n",
    "def toia_answer(query, dataset, k=1):\n",
    "    doc = NLP(query)\n",
    "    # if Greeting, greet\n",
    "    if ['INTJ', 'UH'] in [[token.pos_, token.tag_] for token in doc]:    \n",
    "        if df_greetings.shape[0] > 0:\n",
    "            answers = dataset[dataset['type'] == \"greeting\"].sample(n=1)\n",
    "            return answers['answer'].values[0], answers['id_video'].values[0]\n",
    "        else:\n",
    "            df_noanswers = dataset[dataset['type'] == \"no-answer\"]\n",
    "            if df_noanswers.shape[0] > 0:\n",
    "                answers = df_noanswers.sample(n=1)\n",
    "                return answers['answer'].values[0], answers['id_video'].values[0], \"Record some reetings\"\n",
    "            else:\n",
    "                return \"You haven't recorded greetings nor no-answers\", \"204\", \"No Content\"\n",
    "\n",
    "    querycorpus = []\n",
    "    for i in range(0, len(dataset)):\n",
    "        userquestion = preprocess(dataset['question'][i])\n",
    "        querycorpus.append(userquestion)\n",
    "\n",
    "    # Creating the Bag of Words model with TFIDF and calc cosine_similarity\n",
    "    vectorizer = CountVectorizer(decode_error=\"replace\")\n",
    "    # this is needed to get the attribute vocabulary_\n",
    "    vec_train = vectorizer.fit_transform(querycorpus)\n",
    "    training_vocabulary = vectorizer.vocabulary_\n",
    "    transformer = TfidfTransformer()\n",
    "    trainingvoc_vectorizer = CountVectorizer(\n",
    "        decode_error=\"replace\", vocabulary=training_vocabulary)\n",
    "    tfidf_querycorpus = TfidfVectorizer().fit_transform(querycorpus)\n",
    "\n",
    "    tfidf_userquestion = transformer.fit_transform(\n",
    "        trainingvoc_vectorizer.fit_transform(\n",
    "            numpy.array([\n",
    "                preprocess(query)\n",
    "            ])))\n",
    "    cosine_similarities = cosine_similarity(tfidf_userquestion, tfidf_querycorpus)\n",
    "    related_docs_indices = (-cosine_similarities[0]).argsort()\n",
    "    sorted_freq = cosine_similarities[0][related_docs_indices]\n",
    "\n",
    "    # note for this distance the problem we had befor with inf, we have now with 0. Again we decide\n",
    "    # to make the prediction a bit random. This could be adjusted to remove any 0 distance and\n",
    "    # pick the only ones left if any, and if none predict 1.\n",
    "\n",
    "    if sum(sorted_freq) == 0:\n",
    "        df_noanswers = dataset[dataset['type'] == \"no-answer\"]\n",
    "        if df_noanswers.shape[0] > 0:\n",
    "            answers = df_noanswers.sample(n=1)\n",
    "            return answers['answer'].values[0], answers['id_video'].values[0], \"tfidf all sim 0\"\n",
    "        else:\n",
    "            return \"You haven't recorded no-answers\", \"204\", \"No Content\"\n",
    "    elif sorted_freq[0] > 0.7:  #(the top sorted freq is the max)\n",
    "        if sorted_freq[k-1] != sorted_freq[k] or sorted_freq[k-1] == sorted_freq[k] == 0:\n",
    "            selected = related_docs_indices[:k]\n",
    "            return dataset.iloc[selected[0]]['answer'], dataset.iloc[selected[0]]['id_video'], f\"tfidf sim: {sorted_freq[:k]}\"\n",
    "        else:\n",
    "            indeces = numpy.where(numpy.roll(sorted_freq, 1) != sorted_freq)\n",
    "            selected = related_docs_indices[:indeces[0][indeces[0] >= k][0]]\n",
    "            return dataset.iloc[selected[0]]['answer'], dataset.iloc[selected[0]]['id_video'], f\"tfidf sim: {sorted_freq[:k]}\"\n",
    "\n",
    "    else:\n",
    "        docs = NLP.pipe(dataset['question'].values)\n",
    "        cosine_similarities = [calculate_similarity(query, doc.text) for doc in docs]\n",
    "        if max(cosine_similarities) > 0.5:\n",
    "            related_docs_indices = np.argsort(cosine_similarities)[::-1]\n",
    "            selected = related_docs_indices[:k][0]\n",
    "            return dataset.iloc[selected]['answer'], dataset.iloc[selected]['id_video'], f\"spaCy sim: {cosine_similarities[selected]}\"\n",
    "        else:\n",
    "            df_noanswers = dataset[dataset['type'] == \"no-answer\"]\n",
    "            if df_noanswers.shape[0] > 0:\n",
    "                answers = df_noanswers.sample(n=1)\n",
    "                return answers['answer'].values[0], answers['id_video'].values[0], \"spaCy sim below thr\"\n",
    "            else:\n",
    "                return \"You haven't recorded no-answers\", \"204\", \"No Content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "4cd47cf2-2ea4-42cb-9bc3-9d9127053b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toia_answer(\"Do you like swimming?\", df_avatar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1630e-89fd-4eb7-8d9a-a88c0ad1d7ff",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dee8b9-ebd5-4230-9869-182b193e9f20",
   "metadata": {},
   "source": [
    "## Experiment with Transformers models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485590a0-eeff-4fd8-a502-8c73f5ebd3a2",
   "metadata": {},
   "source": [
    "### Test new function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "e2c2d662-dc85-45b7-bf90-40f67414aa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7080ebce31443c7863e0f97fea42387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/383 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b94c73f46d4dd3aa8a8159d625fc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5a569a09a349b88cb60089b7eacd7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7dbb0145ca4bf68febcd46f1325315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54075b032aed453393aa40ee602c75e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c581f506dd44548fc498430dba2f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\")\n",
    "\n",
    "\n",
    "# #CLS Pooling - Take output from first token\n",
    "# def cls_pooling(model_output):\n",
    "#     return model_output.last_hidden_state[:,0]\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "#Encode text\n",
    "def encode(texts):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    # Perform pooling\n",
    "    # embeddings = cls_pooling(model_output)\n",
    "    embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "5a73a6d0-688d-40df-9e21-e56d2d4763e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode docs\n",
    "doc_emb = encode(df_avatar['answer'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "c24df266-282a-4ec4-b4da-7e4d0d5352bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"what's your name\"\n",
    "# dataset = df_avatar.copy()\n",
    "# k = 1\n",
    "def toia_answer_new(query, dataset, doc_emb, k=5):\n",
    "    doc = NLP(query)\n",
    "    # if Greeting, greet\n",
    "    if ['INTJ', 'UH'] in [[token.pos_, token.tag_] for token in doc]:\n",
    "        if dataset[dataset['type'] == \"greeting\"].shape[0] > 0:\n",
    "            answers = dataset[dataset['type'] == \"greeting\"].sample(n=1)\n",
    "            return answers['question'].values[0], answers['answer'].values[0], answers['id_video'].values[0]\n",
    "        else:\n",
    "            answers = dataset[dataset['type'] == \"no-answer\"].sample(n=1)\n",
    "            return answers['question'].values[0], answers['answer'].values[0], answers['id_video'].values[0], \"No greetings recorded\"\n",
    "\n",
    "    querycorpus = []\n",
    "    for i in range(0, len(dataset)):\n",
    "        userquestion = preprocess(dataset['question'][i])\n",
    "        querycorpus.append(userquestion)\n",
    "\n",
    "    # Creating the Bag of Words model with TFIDF and calc cosine_similarity\n",
    "    vectorizer = CountVectorizer(decode_error=\"replace\")\n",
    "    # this is needed to get the attribute vocabulary_\n",
    "    vec_train = vectorizer.fit_transform(querycorpus)\n",
    "    training_vocabulary = vectorizer.vocabulary_\n",
    "    transformer = TfidfTransformer()\n",
    "    trainingvoc_vectorizer = CountVectorizer(\n",
    "        decode_error=\"replace\", vocabulary=training_vocabulary)\n",
    "    tfidf_querycorpus = TfidfVectorizer().fit_transform(querycorpus)\n",
    "\n",
    "    tfidf_userquestion = transformer.fit_transform(\n",
    "        trainingvoc_vectorizer.fit_transform(\n",
    "            numpy.array([\n",
    "                preprocess(query)\n",
    "            ])))\n",
    "    cosine_similarities = cosine_similarity(tfidf_userquestion, tfidf_querycorpus)\n",
    "    related_docs_indices = (-cosine_similarities[0]).argsort()\n",
    "    sorted_freq = cosine_similarities[0][related_docs_indices]\n",
    "\n",
    "    # note for this distance the problem we had befor with inf, we have now with 0. Again we decide\n",
    "    # to make the prediction a bit random. This could be adjusted to remove any 0 distance and\n",
    "    # pick the only ones left if any, and if none predict 1.\n",
    "\n",
    "    if sum(sorted_freq) == 0:\n",
    "        answers = dataset[dataset['type'] == \"no-answer\"].sample(n=1)\n",
    "        return answers['question'].values[0], answers['answer'].values[0], answers['id_video'].values[0], \"tfidf sim all 0\"\n",
    "\n",
    "    elif sorted_freq[0] > 0.85:  #(the top sorted freq is the max)\n",
    "        if sorted_freq[k-1] != sorted_freq[k] or sorted_freq[k-1] == sorted_freq[k] == 0:\n",
    "            selected = related_docs_indices[:k]\n",
    "            return dataset.iloc[selected[0]]['question'], dataset.iloc[selected[0]]['answer'], dataset.iloc[selected[0]]['id_video'], f\"tfidf sim: {sorted_freq[:k]}\"\n",
    "        else:\n",
    "            indeces = numpy.where(numpy.roll(sorted_freq, 1) != sorted_freq)\n",
    "            selected = related_docs_indices[:indeces[0][indeces[0] >= k][0]]\n",
    "            return dataset.iloc[selected[0]]['question'], dataset.iloc[selected[0]]['answer'], dataset.iloc[selected[0]]['id_video'], f\"tfidf sim: {sorted_freq[:k]}\"\n",
    "\n",
    "    else:\n",
    "        #Encode query\n",
    "        query_emb = encode(query)\n",
    "        #Compute dot score between query and all document embeddings\n",
    "        scores = torch.mm(query_emb, doc_emb.transpose(0, 1))[0].cpu().tolist()\n",
    "        if max(scores) > 0.4:\n",
    "            related_docs_indices = np.argsort(scores)[::-1]\n",
    "            selected = related_docs_indices[:k][0]\n",
    "            return dataset.iloc[selected]['question'], dataset.iloc[selected]['answer'], dataset.iloc[selected]['id_video'], f\"Trsf sim: {scores[selected]}\"\n",
    "        else:\n",
    "            answers = dataset[dataset['type'] == \"no-answer\"].sample(n=1)\n",
    "            return answers['question'].values[0], answers['answer'].values[0], answers['id_video'].values[0], f\"Trsf sim: {max(scores)}\"\n",
    "\n",
    "            \n",
    "# For testing function, convert all 'return' to 'return_a ='\n",
    "# return_a  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "f56947e9-407c-4984-bc71-e94b3a68f088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('What are your hobbies?',\n",
       " 'My hobbies are probably learning, cooking and drawing and singing, But I spend the most time singing and cooking. Probably learning mostly about culture politic.',\n",
       " 'toia181_9_445_3a3c3f91.mp4',\n",
       " 'Trsf sim: 0.4618080258369446')"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toia_answer_new(\"Do you have a hobby?\", df_avatar, doc_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "9b0ae6c4-4193-46a8-bfeb-dfd1dc856f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_toia(dataset, doc_emb):\n",
    "    print(\"TOIA starts\")\n",
    "\n",
    "    while True:\n",
    "        query = input('> ')\n",
    "        if query == \"stop\":\n",
    "            break\n",
    "\n",
    "        output = toia_answer_new(query, dataset, doc_emb)\n",
    "        if output is None:\n",
    "            break\n",
    "\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "a0f76aba-77c3-40dc-a8a5-c998b901693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOIA starts\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello!', 'Hey.', 'toia181_9_378_1b5bde68.mp4')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  what's your name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What is your name?', 'My name is Chloe.', 'toia181_9_250_79387bf3.mp4', 'Trsf sim: 0.6922069787979126')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  nice to meet you, Chloe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What is your name?', 'My name is Chloe.', 'toia181_9_250_79387bf3.mp4', 'Trsf sim: 0.5778009295463562')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Got it. And what do you do?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cannot Answer', \"I don't have an answer to this, but you can ask me about a career, East Asia, or language.\", 'toia181_9_392_7c425ffe.mp4', 'Trsf sim: 0.37391966581344604')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you work or study?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What do you do for a living?', 'I am a student.', 'toia181_9_252_10af5fb6.mp4', 'Trsf sim: 0.4263356029987335')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What do you study?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What do you do for a living?', 'I am a student.', 'toia181_9_252_10af5fb6.mp4', 'Trsf sim: 0.4724082350730896')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Where do you study?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What do you do for a living?', 'I am a student.', 'toia181_9_252_10af5fb6.mp4', 'Trsf sim: 0.4557264447212219')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Where do you live?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Where do you live?', 'Currently I live in Abu Dhabi and the UAE but I move around a lot.', 'toia181_9_439_4b2d7da9.mp4', 'tfidf sim: [0.91662621 0.6603108  0.41312719 0.34525555 0.32417717]')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  do you like Abu Dhabi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What kind of weather do you like?', \"So I don't really like hot weather. I prefer cold weather and in the UAE in Abu Dhabi, it's really hot. So I really am very sad about that.\", 'toia181_9_438_5561328d.mp4', 'Trsf sim: 0.5534321069717407')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  and where do you come from\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Where are you from?', 'I am from the US. And I was born and grew up in Maryland.', 'toia181_9_425_9687414e.mp4', 'Trsf sim: 0.564907431602478')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What do you think about the current situation in the US\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What do you think are the biggest challenges facing the internationalization of our personal lives?', \"I think a lot of people are having a hard time. Adjusting. I think people that do not have a flexible mindset, will have a really hard time with it. And also another issue is probably the globalization of trade, which is good, but also can be bad as we've seen with various issues. We've encountered during this pandemic.\", 'toia181_9_417_9b573275.mp4', 'Trsf sim: 0.4668634831905365')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Did you suffer for the pandemic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Say: I don't have an answer to that right now.\", \"I don't have an answer to that right.\", 'toia181_9_254_e636fa66.mp4', 'Trsf sim: 0.33589035272598267')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you have hobbies or interests?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What are your hobbies?', 'My hobbies are probably learning, cooking and drawing and singing, But I spend the most time singing and cooking. Probably learning mostly about culture politic.', 'toia181_9_445_3a3c3f91.mp4', 'Trsf sim: 0.6188027262687683')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  I love cooking. What is your signature dish?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Do you cook?', 'Yes, I love cooking. And when I can, I cook all the time.', 'toia181_9_441_062ca6ee.mp4', 'Trsf sim: 0.4989738464355469')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Tell me your favorite food\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"What's your favorite food?\", \"I do not have a favorite food because I like eating a variety of food, but I really enjoy like Chinese food and East Asian food in general. But yeah, the best food to me is a new food that I didn't know that I liked.\", 'toia181_9_385_205f6de0.mp4', 'tfidf sim: [0.90541063 0.46270702 0.42422749 0.4149698  0.38544621]')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  sweet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cannot Answer', \"I don't know about this, but I do know a little bit more about international relations.\", 'toia181_9_393_6b1dc931.mp4', 'tfidf sim all 0')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Do you sing professionaly?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Say: Can you try rephrasing the question?', 'Can you try rephrasing the question?', 'toia181_9_259_b4d1b749.mp4', 'Trsf sim: 0.38475584983825684')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What can you sing?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Say: I don't have an answer to that right now.\", \"I don't have an answer to that right.\", 'toia181_9_254_e636fa66.mp4', 'Trsf sim: 0.3048315644264221')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Tell me your favorite music\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cannot Answer', 'Can you try rewording the question?', 'toia181_9_429_d7870fbc.mp4', 'Trsf sim: 0.357465922832489')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  Are there any good Chinese restaurants in Abu Dhabi?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Cannot Answer', \"I don't know the answer to that one.\", 'toia181_9_389_19708085.mp4', 'Trsf sim: 0.36569541692733765')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  What major did you take\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What is your major?', \"I make my own major, but it's like international relations or Regional studies with a focus in East Asia.\", 'toia181_9_435_dbf275f7.mp4', 'Trsf sim: 0.4254029393196106')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  it was nice chatting. Bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello!', 'Ni Hao.', 'toia181_9_377_78029885.mp4')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  bye bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hello!', 'Hello.', 'toia181_9_375_21b37043.mp4')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  goodbye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Goodbye!', 'Hope you have a wonderful day.', 'toia181_9_402_cebf2aa0.mp4', 'tfidf sim: [1.         1.         1.         0.36700623 0.        ]')\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">  stop\n"
     ]
    }
   ],
   "source": [
    "run_toia(df_avatar, doc_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd108ac-5484-4050-978e-b633313ffc99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4370f583-2e6d-4c15-af35-688d36a33c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ed2f287-2bf7-4b24-b5b6-7c2fb53d0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = sr.Microphone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15d77f2e-986c-4fd6-874b-0a493f7e63c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alberto Maria Chiericiâ€™s AirPods Max',\n",
       " 'Alberto Maria Chiericiâ€™s AirPods Max',\n",
       " 'MacBook Pro Microphone',\n",
       " 'MacBook Pro Speakers',\n",
       " 'Multi-Output Device']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92409336-b888-4f27-aeb7-2991ef3bb630",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mic as source:\n",
    "    # r.adjust_for_ambient_noise(source)\n",
    "    audio = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "351aaf49-8296-4ae7-a3a4-84d38137be82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ae20b6d-fb1d-4bec-89ce-ef73423f5db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_toia(dataset):\n",
    "    print(\"TOIA starts\")\n",
    "\n",
    "    while True:\n",
    "        # query = input('> ')\n",
    "        with mic as source:\n",
    "            print(\"you may speak ...\")\n",
    "            # r.adjust_for_ambient_noise(source)\n",
    "            audio = r.listen(source)\n",
    "            query = r.recognize_google(audio)\n",
    "            print(f\"(you said {query})\")\n",
    "        if query == \"stop\":\n",
    "            break\n",
    "\n",
    "        output = toia_answer_new(query, dataset)\n",
    "        if output is None:\n",
    "            break\n",
    "\n",
    "        print(f\"avatar: {output[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4bb6f35f-4ddd-4198-b424-e3fd876c3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOIA starts\n",
      "you may speak ...\n",
      "(you said hello where are you)\n",
      "avatar: hello there. How's it going?\n",
      "you may speak ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yh/m455kn5x5pbgwq0gg3dt4xtc0000gn/T/ipykernel_15125/1924364141.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_toia\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_avatar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/yh/m455kn5x5pbgwq0gg3dt4xtc0000gn/T/ipykernel_15125/3405446147.py\u001b[0m in \u001b[0;36mrun_toia\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"you may speak ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;31m# r.adjust_for_ambient_noise(source)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"(you said {query})\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/toia-dm-mv9iBiCR/lib/python3.8/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mlisten\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[1;32m    650\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                 \u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# reached end of the stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                 \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/toia-dm-mv9iBiCR/lib/python3.8/site-packages/speech_recognition/__init__.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaudio_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/toia-dm-mv9iBiCR/lib/python3.8/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_toia(df_avatar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db9272-4b20-453e-8bff-2aff711905fd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93bca89-98ca-4462-bcc9-7e15de0013f9",
   "metadata": {},
   "source": [
    "## WIP: Can see if an ELIZA-like algorithm can help\n",
    "\n",
    "https://github.com/wadetb/eliza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f211ad7e-149c-462d-a101-ed309b92e538",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9ae8b96c-5a21-4c2d-b1b7-57fdb4fecf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7eff6e57c1e493bbdf443e8d90753cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "643072ebab124eec928607c7a933787d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364115cda4ac4b34b12e716412806faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af22c8d9d95143b38950543c35f84522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a4d4d543444ca48b22719bb0809087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3f8c4989ef540f5a266c835aae5e770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.682628631591797 Around 9 Million people live in London\n",
      "16.253799438476562 London is known for its financial district\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "#CLS Pooling - Take output from first token\n",
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:,0]\n",
    "\n",
    "#Encode text\n",
    "def encode(texts):\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    # Perform pooling\n",
    "    embeddings = cls_pooling(model_output)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "query = \"How many people live in London?\"\n",
    "docs = [\"Around 9 Million people live in London\", \"London is known for its financial district\"]\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "#Encode query and docs\n",
    "query_emb = encode(query)\n",
    "doc_emb = encode(docs)\n",
    "\n",
    "#Compute dot score between query and all document embeddings\n",
    "scores = torch.mm(query_emb, doc_emb.transpose(0, 1))[0].cpu().tolist()\n",
    "\n",
    "#Combine docs & scores\n",
    "doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "#Sort by decreasing score\n",
    "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#Output passages & scores\n",
    "for doc, score in doc_score_pairs:\n",
    "    print(score, doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "1c407375-7f9e-4222-b867-e0babf01adac",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = dataset['answer'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "23e01823-75b3-4d58-9258-fa2fb551164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How old are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "45188539-2725-409d-a1d1-fc7b08c51697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "#Encode docs\n",
    "doc_emb = encode(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "7d37693d-637b-4934-87fb-eeca45e943bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.4882755279541 I was born in Italy in the eighties.\n",
      "16.471439361572266 My name is Alberto.\n",
      "14.996089935302734 I have a wife and three kids.\n",
      "14.484272956848145 I like eating, I'm a foodie and I love exploring new restaurants, New Cuisines and hanging out with friends and very much people oriented person.\n",
      "14.124126434326172 Million Reasons.\n"
     ]
    }
   ],
   "source": [
    "#Encode query\n",
    "query_emb = encode(query)\n",
    "\n",
    "#Compute dot score between query and all document embeddings\n",
    "scores = torch.mm(query_emb, doc_emb.transpose(0, 1))[0].cpu().tolist()\n",
    "\n",
    "#Combine docs & scores\n",
    "doc_score_pairs = list(zip(docs, scores))\n",
    "\n",
    "#Sort by decreasing score\n",
    "doc_score_pairs = sorted(doc_score_pairs, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#Output passages & scores\n",
    "for doc, score in doc_score_pairs[:5]:\n",
    "    print(score, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5cd4b-6918-4d87-93fa-e9063a78b59d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

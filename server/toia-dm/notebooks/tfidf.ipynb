{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeeb555-bc77-4457-bb8f-d1403a06f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1353aae9-ff9d-4967-a1f1-7512dd821948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import re\n",
    "import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import spacy\n",
    "NLP = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18ba4c61-c95d-4488-8a07-9aff189551b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "avatar_id = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e12b33cc-d96d-496e-bb70-c04dccfc4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_url = \"mysql://root@localhost/toia\"\n",
    "\n",
    "\n",
    "engine = db.create_engine(sql_url)\n",
    "connection = engine.connect()\n",
    "metadata = db.MetaData()\n",
    "videos = db.Table('video', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "avatar_kb = db.select([videos]).where(\n",
    "    videos.columns.toia_id == avatar_id,\n",
    "    videos.columns.private == 0,\n",
    "    videos.columns.type.notin_([\"filler\", \"exit\"])\n",
    ")\n",
    "\n",
    "ResultProxy = connection.execute(avatar_kb)\n",
    "ResultSet = ResultProxy.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e88f7e56-4734-4472-8401-f33279ca9122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avatar = pd.DataFrame(ResultSet, \n",
    "             columns=[\n",
    "                 'id_video', \n",
    "                 'type', \n",
    "                 'toia_id', \n",
    "                 'idx', \n",
    "                 'private', \n",
    "                 'question', \n",
    "                 'answer', \n",
    "                 'language', \n",
    "                 'likes', \n",
    "                 'views',\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4f9f0827-9536-4eed-b240-2c4461566bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_video</th>\n",
       "      <th>type</th>\n",
       "      <th>toia_id</th>\n",
       "      <th>idx</th>\n",
       "      <th>private</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>language</th>\n",
       "      <th>likes</th>\n",
       "      <th>views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0b2</td>\n",
       "      <td>answer</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>What is your favorite sport?</td>\n",
       "      <td>I love soccer!</td>\n",
       "      <td>en-US</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a7c</td>\n",
       "      <td>answer</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>What do you study?</td>\n",
       "      <td>I study Computer Science.</td>\n",
       "      <td>en-US</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ef1</td>\n",
       "      <td>answer</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>How are you?</td>\n",
       "      <td>I am fine thanks!</td>\n",
       "      <td>en-US</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r21</td>\n",
       "      <td>answer</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>When is your birthday?</td>\n",
       "      <td>My birthday is in September.</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2a</td>\n",
       "      <td>answer</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>What do you do?</td>\n",
       "      <td>I am doing a Ph.D.</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>r2b</td>\n",
       "      <td>answer</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>How old are you?</td>\n",
       "      <td>I'm 35. Age last birthday</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>r2c</td>\n",
       "      <td>answer</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Tell me something interesting?</td>\n",
       "      <td>I wrote a book about the ethics of artificial ...</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>r2e</td>\n",
       "      <td>greeting</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>hey</td>\n",
       "      <td>how's it going?</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>r2f</td>\n",
       "      <td>greeting</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Hello</td>\n",
       "      <td>Hi!</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>r2h</td>\n",
       "      <td>no-answer</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Sorry, I didn't get that</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>r2m</td>\n",
       "      <td>greeting</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>Howdy</td>\n",
       "      <td>hey, I'm all right</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>r2t</td>\n",
       "      <td>y/n-answer</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>Do you like sushi?</td>\n",
       "      <td>Yes</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>r2y</td>\n",
       "      <td>no-answer</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>I don't have an answer for that</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>r3y</td>\n",
       "      <td>no-answer</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>I can't answer this, sorryyyyy</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>r4t</td>\n",
       "      <td>y/n-answer</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>Do you like swimming?</td>\n",
       "      <td>No</td>\n",
       "      <td>en-US</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_video        type  toia_id  idx  private  \\\n",
       "0       0b2      answer        1    2        0   \n",
       "1       a7c      answer        1    3        0   \n",
       "2       ef1      answer        1    1        0   \n",
       "3       r21      answer        1    6        0   \n",
       "4       r2a      answer        1    7        0   \n",
       "5       r2b      answer        1    8        0   \n",
       "6       r2c      answer        1    9        0   \n",
       "7       r2e    greeting        1   18        0   \n",
       "8       r2f    greeting        1   11        0   \n",
       "9       r2h   no-answer        1   13        0   \n",
       "10      r2m    greeting        1   19        0   \n",
       "11      r2t  y/n-answer        1   14        0   \n",
       "12      r2y   no-answer        1   16        0   \n",
       "13      r3y   no-answer        1   17        0   \n",
       "14      r4t  y/n-answer        1   15        0   \n",
       "\n",
       "                          question  \\\n",
       "0     What is your favorite sport?   \n",
       "1               What do you study?   \n",
       "2                     How are you?   \n",
       "3           When is your birthday?   \n",
       "4                  What do you do?   \n",
       "5                 How old are you?   \n",
       "6   Tell me something interesting?   \n",
       "7                              hey   \n",
       "8                            Hello   \n",
       "9                                    \n",
       "10                           Howdy   \n",
       "11              Do you like sushi?   \n",
       "12                                   \n",
       "13                                   \n",
       "14           Do you like swimming?   \n",
       "\n",
       "                                               answer language  likes  views  \n",
       "0                                      I love soccer!    en-US      2      5  \n",
       "1                           I study Computer Science.    en-US     10     34  \n",
       "2                                   I am fine thanks!    en-US      5     14  \n",
       "3                        My birthday is in September.    en-US      4     20  \n",
       "4                                  I am doing a Ph.D.    en-US      4     20  \n",
       "5                           I'm 35. Age last birthday    en-US      4     20  \n",
       "6   I wrote a book about the ethics of artificial ...    en-US      4     20  \n",
       "7                                     how's it going?    en-US      4     20  \n",
       "8                                                 Hi!    en-US      4     20  \n",
       "9                            Sorry, I didn't get that    en-US      4     20  \n",
       "10                                 hey, I'm all right    en-US      4     20  \n",
       "11                                                Yes    en-US      4     20  \n",
       "12                    I don't have an answer for that    en-US      4     20  \n",
       "13                     I can't answer this, sorryyyyy    en-US      4     20  \n",
       "14                                                 No    en-US      4     20  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avatar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0f1d383b-f0c4-4fcf-8758-3a70d083949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- next doc ---\n",
      "What is your favorite sport?\n",
      "What PRON WP\n",
      "is AUX VBZ\n",
      "your PRON PRP$\n",
      "favorite ADJ JJ\n",
      "sport NOUN NN\n",
      "? PUNCT .\n",
      "--- next doc ---\n",
      "What do you study?\n",
      "What PRON WP\n",
      "do AUX VBP\n",
      "you PRON PRP\n",
      "study VERB VB\n",
      "? PUNCT .\n",
      "--- next doc ---\n",
      "How are you?\n",
      "How ADV WRB\n",
      "are AUX VBP\n",
      "you PRON PRP\n",
      "? PUNCT .\n",
      "--- next doc ---\n",
      "When is your birthday?\n",
      "When ADV WRB\n",
      "is AUX VBZ\n",
      "your PRON PRP$\n",
      "birthday NOUN NN\n",
      "? PUNCT .\n",
      "--- next doc ---\n",
      "What do you do?\n",
      "What PRON WP\n",
      "do AUX VBP\n",
      "you PRON PRP\n",
      "do VERB VB\n",
      "? PUNCT .\n",
      "--- next doc ---\n",
      "How old are you?\n",
      "How ADV WRB\n",
      "old ADJ JJ\n",
      "are AUX VBP\n",
      "you PRON PRP\n",
      "? PUNCT .\n",
      "--- next doc ---\n",
      "Tell me something interesting?\n",
      "Tell VERB VB\n",
      "me PRON PRP\n",
      "something PRON NN\n",
      "interesting ADJ JJ\n",
      "? PUNCT .\n",
      "--- next doc ---\n",
      "hey\n",
      "hey INTJ UH\n",
      "--- next doc ---\n",
      "Hello\n",
      "Hello INTJ UH\n",
      "--- next doc ---\n",
      "\n",
      "--- next doc ---\n",
      "Howdy\n",
      "Howdy INTJ UH\n",
      "Howdy 0 5 PERSON\n",
      "--- next doc ---\n",
      "Do you like sushi?\n",
      "Do AUX VBP\n",
      "you PRON PRP\n",
      "like VERB VB\n",
      "sushi NOUN NN\n",
      "? PUNCT .\n",
      "--- next doc ---\n",
      "\n",
      "--- next doc ---\n",
      "\n",
      "--- next doc ---\n",
      "Do you like swimming?\n",
      "Do AUX VBP\n",
      "you PRON PRP\n",
      "like VERB VB\n",
      "swimming VERB VBG\n",
      "? PUNCT .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "docs = nlp.pipe(df_avatar['question'].values)\n",
    "for doc in docs:\n",
    "    print(\"--- next doc ---\")\n",
    "    print(doc)\n",
    "    for token in doc:\n",
    "        print(token.text, token.pos_, token.tag_)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "ba228ea6-23a1-4fe1-b0d3-a3e837b1ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"hey, hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9074bb1a-720d-41cc-9239-76ea15022d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['INTJ', 'UH'] in [[token.pos_, token.tag_] for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8f0f3649-fba5-4515-abdc-7e84c3e784ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{',', '.', 'UH'}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([token.tag_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3c4f751d-c475-4465-b6c0-7637647fe331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey, I'm all right\""
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avatar[df_avatar['type'] == \"greeting\"].sample(n=1)['answer'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0bb204c7-cd82-4bc9-bec4-d0e3d87f0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = SnowballStemmer('english')\n",
    "\n",
    "def preprocess(text):\n",
    "            # Stem and remove stopwords\n",
    "            text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "            text = text.lower()\n",
    "            text = text.split()\n",
    "            text = [ps.stem(word) for word in text]  # if not word in set(stopwords.words('english'))]\n",
    "            return ' '.join(text)\n",
    "\n",
    "\n",
    "def toia_answer(query, dataset, k=1):\n",
    "    doc = NLP(query)\n",
    "    # if Greeting, greet\n",
    "    if ['INTJ', 'UH'] in [[token.pos_, token.tag_] for token in doc]:\n",
    "        answers = dataset[dataset['type'] == \"greeting\"].sample(n=1)\n",
    "        return answers['answer'].values[0], answers['id_video'].values[0]\n",
    "        \n",
    "    querycorpus = []\n",
    "    for i in range(0, len(df_avatar)):\n",
    "        userquestion = preprocess(df_avatar['question'][i])\n",
    "        querycorpus.append(userquestion)      \n",
    "\n",
    "    # Creating the Bag of Words model with TFIDF and calc cosine_similarity\n",
    "    vectorizer = CountVectorizer(decode_error=\"replace\")\n",
    "    vec_train = vectorizer.fit_transform(querycorpus) #this is needed to get the attribute vocabulary_\n",
    "    training_vocabulary = vectorizer.vocabulary_\n",
    "    transformer = TfidfTransformer()\n",
    "    trainingvoc_vectorizer = CountVectorizer(decode_error=\"replace\", vocabulary=training_vocabulary)\n",
    "    tfidf_querycorpus = TfidfVectorizer().fit_transform(querycorpus)\n",
    "    \n",
    "    tfidf_userquestion = transformer.fit_transform(\n",
    "        trainingvoc_vectorizer.fit_transform(\n",
    "            numpy.array([\n",
    "                preprocess(query)\n",
    "            ]))) \n",
    "    cosine_similarities = cosine_similarity(tfidf_userquestion, tfidf_querycorpus)\n",
    "    related_docs_indices = (-cosine_similarities[0]).argsort()\n",
    "    sorted_freq = cosine_similarities[0][related_docs_indices]\n",
    "    \n",
    "    #note for this distance the problem we had befor with inf, we have now with 0. Again we decide\n",
    "    #to make the prediction a bit random. This could be adjusted to remove any 0 distance and\n",
    "    #pick the only ones left if any, and if none predict 1.\n",
    "    \n",
    "    if sum(sorted_freq)==0:\n",
    "        answers = dataset[dataset['type'] == \"no-answer\"].sample(n=1)\n",
    "        return answers['answer'].values[0], answers['id_video'].values[0]\n",
    "    \n",
    "    elif sorted_freq[k-1]!=sorted_freq[k] or sorted_freq[k-1]==sorted_freq[k]==0:\n",
    "        selected = related_docs_indices[:k]\n",
    "       \n",
    "        return dataset.iloc[selected[0]]['answer'], dataset.iloc[selected[0]]['id_video']\n",
    "    else:\n",
    "        indeces = numpy.where(numpy.roll(sorted_freq,1)!=sorted_freq)\n",
    "        selected = related_docs_indices[:indeces[0][indeces[0]>=k][0]]\n",
    "    \n",
    "        return dataset.iloc[selected[0]]['answer'], dataset.iloc[selected[0]]['id_video']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4cd47cf2-2ea4-42cb-9bc3-9d9127053b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"I can't answer this, sorryyyyy\", 'r3y')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toia_answer(\"hola cachina\", df_avatar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1262a212-e435-4ed8-a7c4-34dee63fcc56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b14530-483d-4437-a5ad-36ec9df0fd3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b46cf2-08eb-426e-a097-0ee5844b28c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

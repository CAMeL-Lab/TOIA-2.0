{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efcf4a2b-b4c9-422b-a59b-5fdbdf399840",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69202d1-e947-45f3-ae07-77345cf2c97f",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf369e8-ebce-4029-a62d-7c99ef321410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[nltk_data] Downloading package punkt to /Users/amc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from flask import Flask, request, render_template, url_for\n",
    "# import os\n",
    "import argparse\n",
    "import random\n",
    "import re\n",
    "import json \n",
    "import linecache\n",
    "from transformers import pipeline, set_seed\n",
    "from transformers import BertTokenizer, BertForNextSentencePrediction\n",
    "import nltk \n",
    "from nltk import tokenize\n",
    "import ssl\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "\n",
    "# #Local storage of the conversation data - will be deprecated once the database is in place\n",
    "# storage = []\n",
    "\n",
    "# starters = [\"What topics would you like to talk about?\", \"What are your hobbies?\", \"Where did you study?\"]\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9294125c-8ea4-4024-bf6c-21f869e26aa4",
   "metadata": {},
   "source": [
    "## Q Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd9b59f-7826-492a-b7fd-fd6b1922984e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2Model were not initialized from the model checkpoint at gpt2 and are newly initialized: ['h.0.attn.masked_bias', 'h.1.attn.masked_bias', 'h.2.attn.masked_bias', 'h.3.attn.masked_bias', 'h.4.attn.masked_bias', 'h.5.attn.masked_bias', 'h.6.attn.masked_bias', 'h.7.attn.masked_bias', 'h.8.attn.masked_bias', 'h.9.attn.masked_bias', 'h.10.attn.masked_bias', 'h.11.attn.masked_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc7242f-e0c9-40d7-af66-674aa862f96f",
   "metadata": {},
   "source": [
    "The function below isn't used for now..."
   ]
  },
  {
   "cell_type": "raw",
   "id": "190e334d-ed97-43c8-a37a-3bb4e9e50c5a",
   "metadata": {},
   "source": [
    "def generateNextQ():\n",
    "\n",
    "    # UNCOMMENT AFTER INTEGRATION WITH BACKEND\n",
    "\n",
    "    body_unicode = request.data.decode('utf-8')\n",
    "    body = json.loads(body_unicode)\n",
    "\n",
    "    print(\"Received body\", body)\n",
    "    text=body['qa_pair']\n",
    "\n",
    "    storage.append(text)\n",
    "\n",
    "    if len(starters) > 0: \n",
    "        print(\"SENDING STARTER\")\n",
    "        return {\"q\":starters.pop()}\n",
    "\n",
    "    else: \n",
    "\n",
    "        text = \" \".join(storage[-2:])\n",
    "        q = generator(text, num_return_sequences=3,max_length=50+len(text))\n",
    "\n",
    "        #all generated examples \n",
    "        allGenerations = \"\"\n",
    "        for i in range(3):\n",
    "            allGenerations = allGenerations +\" \"+ q[i]['generated_text'][len(text)-4:]\n",
    "        \n",
    "        #Separating all the sentences... \n",
    "        sentenceList = nltk.tokenize.sent_tokenize(allGenerations)\n",
    "\n",
    "        #Filter out questions \n",
    "        questionsList = []\n",
    "        for sentence in sentenceList :\n",
    "            if \"?\" in sentence:\n",
    "                questionsList.append(sentence.strip(\"\\n\").strip(\"\\\\\").strip('\"'))\n",
    "\n",
    "        #Bert evaluation\n",
    "        bert_filtered_qs = []\n",
    "        for sentence in questionsList:\n",
    "            encoding = tokenizer(\" \".join(storage[-3:]), sentence, return_tensors='pt')\n",
    "            outputs = model(**encoding)\n",
    "            logits = outputs.logits\n",
    "            bert_filtered_qs.append((logits[0,0].item(), sentence))\n",
    "\n",
    "\n",
    "        bert_filtered_qs.sort(key=lambda tup: tup[0])\n",
    "\n",
    "\n",
    "        print(bert_filtered_qs)\n",
    "\n",
    "        return {\"q\":bert_filtered_qs[-1][1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3711b-36c7-42b3-bc90-f282ced3541d",
   "metadata": {},
   "source": [
    "## Try it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ffa40950-6747-4027-95fa-123e528ba324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "from sqlalchemy.sql import text as QueryText\n",
    "\n",
    "SQL_URL = \"mysql+pymysql://root:ReallyComplicatedPassword@localhost:3307/toia\"\n",
    "\n",
    "ENGINE = db.create_engine(SQL_URL)\n",
    "\n",
    "CONNECTION = ENGINE.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbe5a835-d67a-41d8-a091-661a1fe152d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = QueryText(\n",
    "    \"SELECT question FROM questions \\\n",
    "        WHERE trigger_suggester = 1 \\\n",
    "    ;\"\n",
    ")\n",
    "\n",
    "result_proxy = CONNECTION.execute(statement)\n",
    "\n",
    "result_set = result_proxy.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07756cea-b79d-419c-a191-318581433f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is your name?', 'Where and when were you born?', 'What do you do for a living?']\n"
     ]
    }
   ],
   "source": [
    "starters = [qs[0] for qs in result_set]\n",
    "print(starters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5827d6e-eaf2-4457-b23a-d497aa6357ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('What do you do for a living? I work as a data scientist.',)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONNECTION = ENGINE.connect()  #Need to refresh connection\n",
    "\n",
    "statement = QueryText(\"\"\"\n",
    "    SELECT CONCAT(questions.question, \" \", video.answer) AS latest_question_answer \n",
    "    FROM video\n",
    "    INNER JOIN videos_questions_streams\n",
    "    ON videos_questions_streams.id_video = video.id_video\n",
    "    INNER JOIN questions\n",
    "    ON questions.id = videos_questions_streams.id_question\n",
    "    WHERE toia_id=1 \n",
    "    AND questions.trigger_suggester = 1\n",
    "    ORDER BY video.idx DESC LIMIT 1;\n",
    "    \"\"\")\n",
    "\n",
    "result_proxy = CONNECTION.execute(statement)\n",
    "\n",
    "result_proxy.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "65dc5d89-fdbc-4f99-ae69-33eafd3e08ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_trial_generateNextQ(text, generated_seqs=5):\n",
    "# text = \"What's your name? My name is Alberto.\"\n",
    "    \n",
    "    statement = QueryText(\"\"\"\n",
    "        SELECT CONCAT(questions.question, \" \", video.answer) AS latest_question_answer \n",
    "        FROM video\n",
    "        INNER JOIN videos_questions_streams\n",
    "        ON videos_questions_streams.id_video = video.id_video\n",
    "        INNER JOIN questions\n",
    "        ON questions.id = videos_questions_streams.id_question\n",
    "        WHERE toia_id=1 \n",
    "        AND questions.trigger_suggester = 1\n",
    "        ORDER BY video.idx DESC LIMIT 1;\n",
    "        \"\"\")\n",
    "\n",
    "    CONNECTION = ENGINE.connect()  #Need to refresh connection\n",
    "    result_proxy = CONNECTION.execute(statement)\n",
    "\n",
    "    latest_qa = result_proxy.fetchall()[0][0]\n",
    "\n",
    "    # storage.append(text)\n",
    "\n",
    "    # if len(starters) > 0: \n",
    "    #     print(\"SENDING STARTER\")\n",
    "    #     return {\"q\":starters.pop()}\n",
    "\n",
    "    # else: \n",
    "\n",
    "    # text = \" \".join(storage[-2:])\n",
    "    if len(latest_qa) > 0:\n",
    "        text = latest_qa + text\n",
    "        \n",
    "    q = generator(text, \n",
    "                  num_return_sequences=generated_seqs, \n",
    "                  max_length=50 + len(text))\n",
    "\n",
    "    #all generated examples \n",
    "    allGenerations = \"\"\n",
    "    for i in range(generated_seqs):\n",
    "        allGenerations = allGenerations + \" \" + q[i]['generated_text'][len(text) - 4:]\n",
    "\n",
    "    #Separating all the sentences... \n",
    "    sentenceList = nltk.tokenize.sent_tokenize(allGenerations)\n",
    "\n",
    "    #Filter out questions \n",
    "    questionsList = []\n",
    "    for sentence in sentenceList :\n",
    "        if \"?\" in sentence:\n",
    "            questionsList.append(sentence.strip(\"\\n\").strip(\"\\\\\").strip('\"'))\n",
    "\n",
    "    #Bert evaluation\n",
    "    bert_filtered_qs = []\n",
    "    for sentence in questionsList:\n",
    "        encoding = tokenizer(\" \".join(storage[-3:]), sentence, return_tensors='pt')\n",
    "        outputs = model(**encoding)\n",
    "        logits = outputs.logits\n",
    "        bert_filtered_qs.append((logits[0,0].item(), sentence))\n",
    "\n",
    "\n",
    "    bert_filtered_qs.sort(key=lambda tup: tup[0], reverse=True)\n",
    "\n",
    "    # print(bert_filtered_qs[:5])\n",
    "    # print({\"q\":questionsList})\n",
    "\n",
    "    no_suggestions = min(len(bert_filtered_qs) - 1, 5)\n",
    "\n",
    "    suggestions = [bert_filtered_qs[i][1] for i in range(no_suggestions) if bert_filtered_qs[i][1] != bert_filtered_qs[i + 1][1]]\n",
    "\n",
    "    # return {\"q\":bert_filtered_qs[-1][1]}\n",
    "    return suggestions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f40aa58f-1975-474a-b4aa-e998a1b714ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"In your past work with the cryptocurrency scene, you've had a NYU.What are some ways your students study about a specific topic?\",\n",
       " \"I've studied in a university department.What was your most important job decision?I was looking to work for a job.What was your most recent experience as a data scientist?\",\n",
       " \"I worked on the last 10 years in the data sciences.What's your biggest challenge here?\",\n",
       " 'Where do you keep track?',\n",
       " \"Then I asked if he was willing to work at this company, since we owned several insurance companies now and I'd give NYU.Did you see Dr. Oz?I am going to spend a lot of time at home.I want to be productive, I want to have fun, but all those things we're not able to do is live with our lives and our job.\"]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_trial_generateNextQ(\"Where did you take your degrees from? I've got a Phd at NYU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "577f35f1-273a-433b-aae9-d84810df2754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What is your name? My name is Alberto.', 'Where and when were you born? I was born in Italy the eighties.', 'What do you do? I work as a data scientist.']\n",
      "What do you do? I work as a data scientist. Where did you graduate? At NYUAD\n"
     ]
    }
   ],
   "source": [
    "print(storage)\n",
    "text = \"Where did you graduate? At NYUAD\"\n",
    "storage.append(text)\n",
    "text = \" \".join(storage[-2:])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3817097-53ed-46ae-8d3e-db1863ce6ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello! Hi. What is your name? My name is Alberto. I was born on July 26th and I want to talk with your mother. My name is Irene. I want the name of my father, and his name is Alberto. I was born on July 18th and I want to talk with your sister. My name is Roseie. I'm not sure who Rose will be, but to tell you the truth, we didn't get along until about a year ago. We had a mutual crush on each other, but we all grew up together. Then, suddenly in 2001, it happened that we divorced\"},\n",
       " {'generated_text': \"Hello! Hi. What is your name? My name is Alberto. I'm from Brazil. Hello, everyone. My name is Pablo Cava. I am from Argentina. And I'm from Paraguay. Welcome to our office here in Brazil. I want to ask you a couple of questions.\\n\\nYou said to us just after this was announced, before we had the final episode, that you would be coming back and taking a break. So what's your name today?\\n\\nThis is the name of my first name, José Cava. This is what I did back when we got out of Brazil. So\"},\n",
       " {'generated_text': \"Hello! Hi. What is your name? My name is Alberto. We are brothers and sisters. We have two children and two great kids. I have to tell you something. It's good that we are siblings. And it's okay that we have a good name. I will always remember that little miss. When we met, we were all talking about her. She loved dogs and cats. But she did not like boys. So we started doing shows together and he would call her Alberto. But it wasn't always with him. When I heard him tell us everything about her, it made me think that maybe her\"}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"What is your name? My name is Alberto.\", num_return_sequences=3, max_length=50 + len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "121871c4-5623-499e-8592-e86db5920ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'What do you do? I work as a data scientist. Where did you graduate? At NYUADU?\\n\\n\\nBryan: I got my BA from New York City Law School, and I worked with [David] Sutter at the University of California, Berkeley. It was a perfect semester. I applied to law school in a few years. When I applied to law class after class, I went to law school as an undergrad, doing a lot of work. But when I was in grad school, I did some more law. I had some experience in litigation and litigation for a company called Glynn (Hicks'},\n",
       " {'generated_text': \"What do you do? I work as a data scientist. Where did you graduate? At NYUAD?\\n\\nI moved back to NYC where I still worked with John Zetterbeck as VP of Marketing. He didn't have an MBA from NYU, but had started out as a data scientist (as they say). I'm a scientist with a passion to solve problems. I had a master's degree last year in analytics from NYUAD, which means I'm working from that class of NYU students, and doing an internship. So I'm really fortunate.\\n\\nDo you make any business decisions when writing your thesis?\\n\"},\n",
       " {'generated_text': \"What do you do? I work as a data scientist. Where did you graduate? At NYUAD? Is there any job for you?\\n\\nMy job, if I get a job, I'll go to NYU. Yes, there may be a job. I work all these different kinds of jobs in different countries, some in North America, others not there. So there may be three different jobs where I can do these different things. I can go over to a different university, take some courses and study with a professor of biology, work with a professor of applied mathematics, do some math. I might be doing these\"},\n",
       " {'generated_text': 'What do you do? I work as a data scientist. Where did you graduate? At NYUADM. I\\'ve worked as a social science analyst. What are you doing now that you\\'re actually part of the conversation?\\n\\nI want to know why you\\'re doing what you\\'re doing. I didn\\'t want to leave because I thought I had this right. If I didn\\'t want to do something and the answer is, \"Well I really like you, but it won\\'t work out with you\", this is why you need to find a new person, I think that\\'s just fine. You can find something new'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(text, num_return_sequences=4, max_length=50 + len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5481bd5f-d8cc-4ed1-8e27-9d7717b746ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
